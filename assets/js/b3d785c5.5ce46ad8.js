"use strict";(self.webpackChunkdocusaurus_yt_example=self.webpackChunkdocusaurus_yt_example||[]).push([[9527],{3905:(e,n,t)=>{t.d(n,{Zo:()=>u,kt:()=>m});var a=t(7294);function i(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function r(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){i(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,a,i=function(e,n){if(null==e)return{};var t,a,i={},o=Object.keys(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||(i[t]=e[t]);return i}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}var p=a.createContext({}),s=function(e){var n=a.useContext(p),t=n;return e&&(t="function"==typeof e?e(n):r(r({},n),e)),t},u=function(e){var n=s(e.components);return a.createElement(p.Provider,{value:n},e.children)},g="mdxType",c={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},d=a.forwardRef((function(e,n){var t=e.components,i=e.mdxType,o=e.originalType,p=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),g=s(t),d=i,m=g["".concat(p,".").concat(d)]||g[d]||c[d]||o;return t?a.createElement(m,r(r({ref:n},u),{},{components:t})):a.createElement(m,r({ref:n},u))}));function m(e,n){var t=arguments,i=n&&n.mdxType;if("string"==typeof e||i){var o=t.length,r=new Array(o);r[0]=d;var l={};for(var p in n)hasOwnProperty.call(n,p)&&(l[p]=n[p]);l.originalType=e,l[g]="string"==typeof e?e:i,r[1]=l;for(var s=2;s<o;s++)r[s]=t[s];return a.createElement.apply(null,r)}return a.createElement.apply(null,t)}d.displayName="MDXCreateElement"},1115:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>p,contentTitle:()=>r,default:()=>c,frontMatter:()=>o,metadata:()=>l,toc:()=>s});var a=t(7462),i=(t(7294),t(3905));const o={},r="Creating AI Applications using Langchain and Hugging Face",l={unversionedId:"Creating AI applications/intro",id:"Creating AI applications/intro",title:"Creating AI Applications using Langchain and Hugging Face",description:"In today's rapidly evolving world, AI automation is becoming an integral part of our lives. Many of the tasks we encounter daily are now automated using AI technologies. In this tutorial, we will explore how to create Generative AI models using Langchain and Hugging Face APIs. Specifically, we will build applications using the GPT-2 model, an open-source language model developed by OpenAI.",source:"@site/docs/Creating AI applications/intro.md",sourceDirName:"Creating AI applications",slug:"/Creating AI applications/intro",permalink:"/gen-ai/docs/Creating AI applications/intro",draft:!1,editUrl:"https://github.com/facebook/docusaurus/edit/main/website/docs/Creating AI applications/intro.md",tags:[],version:"current",frontMatter:{},sidebar:"mySidebar",previous:{title:"Image Captioning App",permalink:"/gen-ai/docs/imgcap/intro"},next:{title:"Image Generation",permalink:"/gen-ai/docs/imagegen/imagegenintro"}},p={},s=[{value:"Getting Started",id:"getting-started",level:2},{value:"Translating English to SQL Model",id:"translating-english-to-sql-model",level:2},{value:"Building a Text Prompt Language Model",id:"building-a-text-prompt-language-model",level:2},{value:"Conclusion",id:"conclusion",level:2}],u={toc:s},g="wrapper";function c(e){let{components:n,...t}=e;return(0,i.kt)(g,(0,a.Z)({},u,t,{components:n,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"creating-ai-applications-using-langchain-and-hugging-face"},"Creating AI Applications using Langchain and Hugging Face"),(0,i.kt)("p",null,"In today's rapidly evolving world, AI automation is becoming an integral part of our lives. Many of the tasks we encounter daily are now automated using AI technologies. In this tutorial, we will explore how to create Generative AI models using Langchain and Hugging Face APIs. Specifically, we will build applications using the GPT-2 model, an open-source language model developed by OpenAI."),(0,i.kt)("h2",{id:"getting-started"},"Getting Started"),(0,i.kt)("p",null,"To begin, let's import the necessary libraries. We will be using Langchain and Hugging Face libraries to build our applications."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"# Installing required libraries\npip install langchain\npip install python-dotenv\n")),(0,i.kt)("p",null,"Next, we need to log in to the Hugging Face platform to access their APIs. You can visit their ",(0,i.kt)("a",{parentName:"p",href:"https://huggingface.co/"},"website")," to create an account and generate a secret token, which you'll store in an environment variable file (",(0,i.kt)("inlineCode",{parentName:"p"},".env"),")."),(0,i.kt)("h2",{id:"translating-english-to-sql-model"},"Translating English to SQL Model"),(0,i.kt)("p",null,"In this example, we will build a Language Model (LLM) to translate English text into SQL commands. We will utilize the ",(0,i.kt)("inlineCode",{parentName:"p"},"mrm8488/t5-base-finetuned-wikiSQL")," model from Hugging Face."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'from dotenv import load_dotenv\nfrom langchain import HuggingFaceHub, LLMChain\nfrom langchain.prompts import PromptTemplate\n\nload_dotenv()\n\nhub_llm = HuggingFaceHub(repo_id="mrm8488/t5-base-finetuned-wikiSQL")\n\nprompt = PromptTemplate(\n    input_variables=["question"],\n    template="Translate English to SQL: {question}"\n)\n\nhub_chain = LLMChain(prompt=prompt, llm=hub_llm, verbose=True)\nprint(hub_chain.run("What is the average age of the respondents using a mobile device?"))\n')),(0,i.kt)("p",null,"In this code, we utilize prompt templates to interact with the model. The template guides the user in providing input, making the process more intuitive."),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Note:")," The query might take some time to process due to the use of GPT-2. For faster results, consider using GPT-3 or newer models."),(0,i.kt)("h2",{id:"building-a-text-prompt-language-model"},"Building a Text Prompt Language Model"),(0,i.kt)("p",null,"Now, let's build a Language Model that completes a given text prompt. We will also explore how to adjust the tone and length of the output. For this example, we will use the ",(0,i.kt)("inlineCode",{parentName:"p"},"gpt2")," model from Hugging Face."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'from dotenv import load_dotenv\nfrom langchain import HuggingFaceHub, LLMChain\nfrom langchain.prompts import PromptTemplate\n\nload_dotenv()\n\nhub_llm = HuggingFaceHub(repo_id="gpt2")\n\nprompt = PromptTemplate(\n    input_variables=["profession"],\n    template="You had one job! You are the {profession}, and you are not expected to behave like this."\n)\n\nhub_chain = LLMChain(prompt=prompt, llm=hub_llm, verbose=True, model_kwargs={\'temperature\': 0.8, \'max_length\': 100})\nprint(hub_chain.run("CEO of this company"))\nprint(hub_chain.run("Politician"))\nprint(hub_chain.run("Customer service"))\nprint(hub_chain.run("Insurance Agent"))\n')),(0,i.kt)("p",null,"In this code, we create a template that generates responses based on the given profession. We also adjust the temperature and maximum length of the output to control the tone and length of the generated text."),(0,i.kt)("h2",{id:"conclusion"},"Conclusion"),(0,i.kt)("p",null,"In this tutorial, we explored how to create AI applications using Langchain and Hugging Face APIs. We built two examples: one for translating English to SQL using the ",(0,i.kt)("inlineCode",{parentName:"p"},"mrm8488/t5-base-finetuned-wikiSQL")," model and another for generating text responses based on a given profession using the ",(0,i.kt)("inlineCode",{parentName:"p"},"gpt2")," model. By utilizing these tools and pre-existing models, we can develop powerful and creative AI applications for various use cases."))}c.isMDXComponent=!0}}]);